{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 121315\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function for generating regression data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_data(n_samples, n_features, pos_important_coefficients, neg_important_coefficients, not_important_coefficients, noise=None, random_state=None):\n",
    "    \"\"\"\n",
    "    Generate synthetic regression data with custom coefficients for features, divided into three categories: \n",
    "    - Positive important coefficients (features that contribute positively to the target).\n",
    "    - Negative important coefficients (features that contribute negatively to the target).\n",
    "    - Not important coefficients (features that have no effect on the target).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        The number of data samples to generate (i.e., rows in the feature matrix `X`).\n",
    "    \n",
    "    n_features : int\n",
    "        The total number of features to generate for each sample (i.e., columns in `X`).\n",
    "    \n",
    "    pos_important_coefficients : array-like\n",
    "        An array containing the coefficients for features that positively contribute to the target variable `y`. \n",
    "        These coefficients should be positive values.\n",
    "    \n",
    "    neg_important_coefficients : array-like\n",
    "        An array containing the coefficients for features that negatively contribute to the target variable `y`. \n",
    "        These coefficients should be negative values.\n",
    "    \n",
    "    not_important_coefficients : array-like\n",
    "        An array of zeros representing features that do not contribute to the target variable `y` (i.e., coefficients with zero value).\n",
    "    \n",
    "    noise : float or None, optional (default=None)\n",
    "        The level of noise to add to the generated target `y`. If specified, random noise scaled by this factor is added to the target variable. If `None`, no noise is added.\n",
    "    \n",
    "    random_state : int or None, optional (default=None)\n",
    "        Random seed used to control reproducibility. If `None`, the random state is not fixed.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : numpy.ndarray of shape (n_samples, n_features)\n",
    "        The generated feature matrix where each row represents a sample and each column represents a feature.\n",
    "    \n",
    "    y : numpy.ndarray of shape (n_samples,)\n",
    "        The target variable calculated as a weighted sum of `X` and the coefficients, with optional noise added.\n",
    "    \n",
    "    coefficients : numpy.ndarray of shape (n_features,)\n",
    "        The combined and shuffled array of coefficients used to generate `y`. \n",
    "        This includes the positive, negative, and non-important coefficients.\n",
    "    \n",
    "    informative_indices_pos : list\n",
    "        A list of indices where the corresponding coefficient was positively important (i.e., in the range (0, 1]).\n",
    "    \n",
    "    informative_indices_neg : list\n",
    "        A list of indices where the corresponding coefficient was negatively important (i.e., in the range [-1, 0)).\n",
    "    \n",
    "    not_informative_indices : list\n",
    "        A list of indices where the corresponding coefficient was not important (i.e., exactly 0).\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    # Generating data with 100 samples and 10 features. \n",
    "    # There are 3 positive coefficients, 2 negative, and 5 zero-coefficients.\n",
    "    \n",
    "    X, y, coefficients, pos_idx, neg_idx, zero_idx = generate_dummy_data(\n",
    "        n_samples=100,\n",
    "        n_features=10,\n",
    "        pos_important_coefficients=[0.8, 0.6, 0.9],\n",
    "        neg_important_coefficients=[-0.5, -0.7],\n",
    "        not_important_coefficients=[0, 0, 0, 0, 0],\n",
    "        noise=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    # Generate features\n",
    "    X = rng.uniform(0, 1, size=(n_samples, n_features))\n",
    "    \n",
    "    # Combine coefficients for all groups\n",
    "    coefficients = np.concatenate((pos_important_coefficients, neg_important_coefficients, not_important_coefficients))\n",
    "    np.random.shuffle(coefficients)\n",
    "    \n",
    "    # Generate target variable\n",
    "    y = np.dot(X, coefficients) + noise * rng.uniform(0,1,n_samples)\n",
    "    \n",
    "    # Initialize arrays to store indices\n",
    "    informative_indices_pos = []\n",
    "    informative_indices_neg = []\n",
    "    not_informative_indices = []\n",
    "    \n",
    "    # Loop through coefficients and store indices based on value ranges\n",
    "    for idx, coef in enumerate(coefficients):\n",
    "        if 0 < coef <= 1:\n",
    "            informative_indices_pos.append(idx)\n",
    "        elif -1 <= coef < 0:\n",
    "            informative_indices_neg.append(idx)\n",
    "        elif coef == 0:\n",
    "            not_informative_indices.append(idx)\n",
    "    \n",
    "    return X, y, coefficients, informative_indices_pos, informative_indices_neg, not_informative_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the function to generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.63594305  0.          0.          0.17525386 -0.7779082   0.\n",
      " -0.98291919  0.          0.48170357  0.7238502   0.         -0.21442003\n",
      " -0.87306332 -0.15549965  0.32973782 -0.22460473 -0.97047831  0.37892692\n",
      "  0.81156204  0.63564602  0.         -0.16655291 -0.77061304 -0.87683527\n",
      "  0.17308415  0.          0.          0.         -0.30745003  0.\n",
      "  0.93122506  0.17187668  0.          0.90455584  0.30156601 -0.55837463\n",
      "  0.25841627 -0.12286427 -0.50009029  0.          0.92548    -0.44311534\n",
      " -0.78587031  0.         -0.37503585  0.          0.          0.\n",
      "  0.13982232  0.          0.15928465  0.          0.          0.\n",
      "  0.51518631  0.72449458  0.          0.36992233  0.          0.66507627\n",
      "  0.         -0.19668351  0.60565399  0.21906226 -0.1481139   0.63921096\n",
      " -0.15240682  0.          0.306101   -0.70343462  0.87187095  0.\n",
      " -0.37274027  0.86212381 -0.3783923  -0.27720116  0.          0.15689642\n",
      " -0.54133773 -0.25543164 -0.29481967  0.          0.18949333 -0.19345734\n",
      "  0.          0.16186462]\n",
      "Indices of positive important coefficients: [3, 8, 9, 14, 17, 18, 19, 24, 30, 31, 33, 34, 36, 40, 48, 50, 54, 55, 57, 59, 62, 63, 65, 68, 70, 73, 77, 82, 85]\n",
      "Indices of negative important coefficients: [0, 4, 6, 11, 12, 13, 15, 16, 21, 22, 23, 28, 35, 37, 38, 41, 42, 44, 61, 64, 66, 69, 72, 74, 75, 78, 79, 80, 83]\n",
      "Indices of not important coefficients: [1, 2, 5, 7, 10, 20, 25, 26, 27, 29, 32, 39, 43, 45, 46, 47, 49, 51, 52, 53, 56, 58, 60, 67, 71, 76, 81, 84]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 27857\n",
    "n_features = 86\n",
    "\n",
    "pos_important_coefficients = np.random.uniform(0.1, 1, 29)\n",
    "neg_important_coefficients = np.random.uniform(-1, -0.1, 29)\n",
    "not_important_coefficients = np.zeros(28)\n",
    "\n",
    "X_custom, y_custom, coef_custom, pos_important_indices, neg_important_indices, not_important_indices = generate_dummy_data(n_samples=n_samples, n_features=n_features, pos_important_coefficients=pos_important_coefficients, neg_important_coefficients=neg_important_coefficients, not_important_coefficients=not_important_coefficients, noise=0.00)\n",
    "\n",
    "print(\"Coefficients:\", coef_custom)\n",
    "print(\"Indices of positive important coefficients:\", pos_important_indices)\n",
    "print(\"Indices of negative important coefficients:\", neg_important_indices)\n",
    "print(\"Indices of not important coefficients:\", not_important_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dummy data and corresponding coefficients of the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef = pd.DataFrame({'Coefficient': coef_custom, 'Index': range(len(coef_custom))})\n",
    "df_coef.to_pickle('df_coef.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('coef_array.pkl', 'wb') as f:\n",
    "    pickle.dump(coef_custom, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>feature_79</th>\n",
       "      <th>feature_80</th>\n",
       "      <th>feature_81</th>\n",
       "      <th>feature_82</th>\n",
       "      <th>feature_83</th>\n",
       "      <th>feature_84</th>\n",
       "      <th>feature_85</th>\n",
       "      <th>feature_86</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.211067</td>\n",
       "      <td>0.856305</td>\n",
       "      <td>0.423385</td>\n",
       "      <td>0.933193</td>\n",
       "      <td>0.376651</td>\n",
       "      <td>0.688933</td>\n",
       "      <td>0.778908</td>\n",
       "      <td>0.477010</td>\n",
       "      <td>0.700582</td>\n",
       "      <td>0.096945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617012</td>\n",
       "      <td>0.353717</td>\n",
       "      <td>0.690478</td>\n",
       "      <td>0.077228</td>\n",
       "      <td>0.548231</td>\n",
       "      <td>0.045505</td>\n",
       "      <td>0.974648</td>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.148638</td>\n",
       "      <td>-0.713859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108817</td>\n",
       "      <td>0.158638</td>\n",
       "      <td>0.763131</td>\n",
       "      <td>0.366142</td>\n",
       "      <td>0.588922</td>\n",
       "      <td>0.798592</td>\n",
       "      <td>0.056710</td>\n",
       "      <td>0.360544</td>\n",
       "      <td>0.612287</td>\n",
       "      <td>0.837975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551043</td>\n",
       "      <td>0.338840</td>\n",
       "      <td>0.401196</td>\n",
       "      <td>0.265168</td>\n",
       "      <td>0.102674</td>\n",
       "      <td>0.621692</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>0.846777</td>\n",
       "      <td>0.606630</td>\n",
       "      <td>1.518505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388005</td>\n",
       "      <td>0.049193</td>\n",
       "      <td>0.225762</td>\n",
       "      <td>0.077234</td>\n",
       "      <td>0.921318</td>\n",
       "      <td>0.945317</td>\n",
       "      <td>0.041298</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.582715</td>\n",
       "      <td>0.779889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180831</td>\n",
       "      <td>0.163115</td>\n",
       "      <td>0.543139</td>\n",
       "      <td>0.802616</td>\n",
       "      <td>0.468819</td>\n",
       "      <td>0.894124</td>\n",
       "      <td>0.550438</td>\n",
       "      <td>0.897475</td>\n",
       "      <td>0.417030</td>\n",
       "      <td>0.629713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.302404</td>\n",
       "      <td>0.115896</td>\n",
       "      <td>0.788347</td>\n",
       "      <td>0.700772</td>\n",
       "      <td>0.651147</td>\n",
       "      <td>0.209887</td>\n",
       "      <td>0.405758</td>\n",
       "      <td>0.193929</td>\n",
       "      <td>0.873774</td>\n",
       "      <td>0.724749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216003</td>\n",
       "      <td>0.807926</td>\n",
       "      <td>0.423629</td>\n",
       "      <td>0.726326</td>\n",
       "      <td>0.810544</td>\n",
       "      <td>0.736725</td>\n",
       "      <td>0.453691</td>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.980885</td>\n",
       "      <td>0.187191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.471601</td>\n",
       "      <td>0.084490</td>\n",
       "      <td>0.241151</td>\n",
       "      <td>0.787130</td>\n",
       "      <td>0.994776</td>\n",
       "      <td>0.620574</td>\n",
       "      <td>0.883916</td>\n",
       "      <td>0.297099</td>\n",
       "      <td>0.147879</td>\n",
       "      <td>0.756186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864682</td>\n",
       "      <td>0.427565</td>\n",
       "      <td>0.936642</td>\n",
       "      <td>0.105763</td>\n",
       "      <td>0.917179</td>\n",
       "      <td>0.092923</td>\n",
       "      <td>0.611967</td>\n",
       "      <td>0.062273</td>\n",
       "      <td>0.287476</td>\n",
       "      <td>-0.493460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27852</th>\n",
       "      <td>0.541447</td>\n",
       "      <td>0.076694</td>\n",
       "      <td>0.191292</td>\n",
       "      <td>0.957523</td>\n",
       "      <td>0.655240</td>\n",
       "      <td>0.750578</td>\n",
       "      <td>0.835717</td>\n",
       "      <td>0.801304</td>\n",
       "      <td>0.939088</td>\n",
       "      <td>0.787465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878235</td>\n",
       "      <td>0.580967</td>\n",
       "      <td>0.749924</td>\n",
       "      <td>0.909567</td>\n",
       "      <td>0.272238</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.909523</td>\n",
       "      <td>0.414757</td>\n",
       "      <td>0.888203</td>\n",
       "      <td>1.132753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27853</th>\n",
       "      <td>0.050826</td>\n",
       "      <td>0.658888</td>\n",
       "      <td>0.660791</td>\n",
       "      <td>0.121189</td>\n",
       "      <td>0.589735</td>\n",
       "      <td>0.527047</td>\n",
       "      <td>0.262764</td>\n",
       "      <td>0.334694</td>\n",
       "      <td>0.044825</td>\n",
       "      <td>0.278862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455876</td>\n",
       "      <td>0.472661</td>\n",
       "      <td>0.948820</td>\n",
       "      <td>0.787206</td>\n",
       "      <td>0.138194</td>\n",
       "      <td>0.797808</td>\n",
       "      <td>0.290750</td>\n",
       "      <td>0.059970</td>\n",
       "      <td>0.060240</td>\n",
       "      <td>-1.876087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27854</th>\n",
       "      <td>0.286700</td>\n",
       "      <td>0.468533</td>\n",
       "      <td>0.089225</td>\n",
       "      <td>0.181216</td>\n",
       "      <td>0.694029</td>\n",
       "      <td>0.274736</td>\n",
       "      <td>0.531953</td>\n",
       "      <td>0.827450</td>\n",
       "      <td>0.603869</td>\n",
       "      <td>0.459552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695792</td>\n",
       "      <td>0.893947</td>\n",
       "      <td>0.561364</td>\n",
       "      <td>0.710640</td>\n",
       "      <td>0.759805</td>\n",
       "      <td>0.456218</td>\n",
       "      <td>0.099488</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>0.536682</td>\n",
       "      <td>1.340582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27855</th>\n",
       "      <td>0.748162</td>\n",
       "      <td>0.899440</td>\n",
       "      <td>0.600394</td>\n",
       "      <td>0.868040</td>\n",
       "      <td>0.680574</td>\n",
       "      <td>0.130774</td>\n",
       "      <td>0.223466</td>\n",
       "      <td>0.137248</td>\n",
       "      <td>0.012350</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188691</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>0.480876</td>\n",
       "      <td>0.841159</td>\n",
       "      <td>0.813381</td>\n",
       "      <td>0.479295</td>\n",
       "      <td>0.362349</td>\n",
       "      <td>0.654077</td>\n",
       "      <td>0.477326</td>\n",
       "      <td>0.047151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27856</th>\n",
       "      <td>0.278159</td>\n",
       "      <td>0.332154</td>\n",
       "      <td>0.829999</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.261746</td>\n",
       "      <td>0.719232</td>\n",
       "      <td>0.136514</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.639053</td>\n",
       "      <td>0.547989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228754</td>\n",
       "      <td>0.098155</td>\n",
       "      <td>0.203237</td>\n",
       "      <td>0.905573</td>\n",
       "      <td>0.642120</td>\n",
       "      <td>0.691150</td>\n",
       "      <td>0.192569</td>\n",
       "      <td>0.109088</td>\n",
       "      <td>0.979494</td>\n",
       "      <td>2.677693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27857 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0       0.211067   0.856305   0.423385   0.933193   0.376651   0.688933   \n",
       "1       0.108817   0.158638   0.763131   0.366142   0.588922   0.798592   \n",
       "2       0.388005   0.049193   0.225762   0.077234   0.921318   0.945317   \n",
       "3       0.302404   0.115896   0.788347   0.700772   0.651147   0.209887   \n",
       "4       0.471601   0.084490   0.241151   0.787130   0.994776   0.620574   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "27852   0.541447   0.076694   0.191292   0.957523   0.655240   0.750578   \n",
       "27853   0.050826   0.658888   0.660791   0.121189   0.589735   0.527047   \n",
       "27854   0.286700   0.468533   0.089225   0.181216   0.694029   0.274736   \n",
       "27855   0.748162   0.899440   0.600394   0.868040   0.680574   0.130774   \n",
       "27856   0.278159   0.332154   0.829999   0.019400   0.261746   0.719232   \n",
       "\n",
       "       feature_7  feature_8  feature_9  feature_10  ...  feature_78  \\\n",
       "0       0.778908   0.477010   0.700582    0.096945  ...    0.617012   \n",
       "1       0.056710   0.360544   0.612287    0.837975  ...    0.551043   \n",
       "2       0.041298   0.157639   0.582715    0.779889  ...    0.180831   \n",
       "3       0.405758   0.193929   0.873774    0.724749  ...    0.216003   \n",
       "4       0.883916   0.297099   0.147879    0.756186  ...    0.864682   \n",
       "...          ...        ...        ...         ...  ...         ...   \n",
       "27852   0.835717   0.801304   0.939088    0.787465  ...    0.878235   \n",
       "27853   0.262764   0.334694   0.044825    0.278862  ...    0.455876   \n",
       "27854   0.531953   0.827450   0.603869    0.459552  ...    0.695792   \n",
       "27855   0.223466   0.137248   0.012350    0.033816  ...    0.188691   \n",
       "27856   0.136514   0.005961   0.639053    0.547989  ...    0.228754   \n",
       "\n",
       "       feature_79  feature_80  feature_81  feature_82  feature_83  feature_84  \\\n",
       "0        0.353717    0.690478    0.077228    0.548231    0.045505    0.974648   \n",
       "1        0.338840    0.401196    0.265168    0.102674    0.621692    0.087930   \n",
       "2        0.163115    0.543139    0.802616    0.468819    0.894124    0.550438   \n",
       "3        0.807926    0.423629    0.726326    0.810544    0.736725    0.453691   \n",
       "4        0.427565    0.936642    0.105763    0.917179    0.092923    0.611967   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "27852    0.580967    0.749924    0.909567    0.272238    0.988751    0.909523   \n",
       "27853    0.472661    0.948820    0.787206    0.138194    0.797808    0.290750   \n",
       "27854    0.893947    0.561364    0.710640    0.759805    0.456218    0.099488   \n",
       "27855    0.049275    0.480876    0.841159    0.813381    0.479295    0.362349   \n",
       "27856    0.098155    0.203237    0.905573    0.642120    0.691150    0.192569   \n",
       "\n",
       "       feature_85  feature_86    target  \n",
       "0        0.263900    0.148638 -0.713859  \n",
       "1        0.846777    0.606630  1.518505  \n",
       "2        0.897475    0.417030  0.629713  \n",
       "3        0.992162    0.980885  0.187191  \n",
       "4        0.062273    0.287476 -0.493460  \n",
       "...           ...         ...       ...  \n",
       "27852    0.414757    0.888203  1.132753  \n",
       "27853    0.059970    0.060240 -1.876087  \n",
       "27854    0.666659    0.536682  1.340582  \n",
       "27855    0.654077    0.477326  0.047151  \n",
       "27856    0.109088    0.979494  2.677693  \n",
       "\n",
       "[27857 rows x 87 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_custom, columns=[f\"feature_{i+1}\" for i in range(n_features)])\n",
    "df['target'] = y_custom\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('df_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"positive_correlated_features_idx\"\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(pos_important_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"negative_correlated_features_idx\"\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(neg_important_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"not_correlated_features_idx\"\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(not_important_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotXAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
